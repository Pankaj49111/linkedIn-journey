{
  "post_text": "We trust our metrics, always. Then production screams.\n\nI own the core API stack. We meticulously defined our SLO: 99.9% of `/v1/checkout` requests must resolve under 1000ms . I felt completely confident in that boundary. It covered the most critical user path.\n\nThen the outage hit. PagerDuty erupted with user complaints about stalled payments. I stared at the dashboard. Our P99 latency metric was green, fluctuating around 950ms. Error rates were flat zero. The system was \u2018healthy.\u2019\n\nThe contradiction was deafening. I assumed P99 latency measured at the ingress point fully captured the user's perception of \u201cslowness.\u201d Why were users seeing timeouts if our backend was passing the threshold?\n\nAfter an hour of fruitless debugging, I shifted focus to the client-side trace logs. That\u2019s when it clicked. Our SLI only measured the primary payment call. The subsequent 4 low-priority configuration lookups, while individually fast , ran sequentially.\n\nTheir cumulative P99 duration added 1.5 seconds of invisible lag to the total user transaction time \ud83e\udd26. Our metric was lying to us about the actual experience.\n\n\n\nThe Moral \ud83d\udc47\nThe closer your SLI is to the user\u2019s reality, the more useful it is during a crisis.",
  "lesson_extracted": "The closer your SLI is to the user\u2019s reality, the more useful it is during a crisis.",
  "meta_theme": "THE METRIC LIE \ud83d\udcca",
  "meta_tech": "SLIs/SLOs"
}